{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>injects just enough freshness into the proceed...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>that</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>never plays as dramatic even when dramatic thi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None of this is very original , and it is n't ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>, Madonna gives her best performance since Abe...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Phrase  Sentiment\n",
       "0  injects just enough freshness into the proceed...          3\n",
       "1                                               that          2\n",
       "2  never plays as dramatic even when dramatic thi...          0\n",
       "3  None of this is very original , and it is n't ...          0\n",
       "4  , Madonna gives her best performance since Abe...          3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('sentiment_5_class.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.Phrase.tolist()\n",
    "y = df.Sentiment.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14711 3678\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1, stratify = y)\n",
    "print(len(X_train), len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(242, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#c_vectorizer = CountVectorizer()\n",
    "#c_vectorizer.fit(X_train)\n",
    "#c_vectorizer.get_feature_names()\n",
    "\n",
    "#c_vectorizer = CountVectorizer()\n",
    "#c_vectorizer.fit(X_train)\n",
    "#c_vectorizer.get_feature_names()\n",
    "\n",
    "#c_X_train_v.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "t_vectorizer = TfidfVectorizer()\n",
    "t_vectorizer.fit(X_train)\n",
    "#t_vectorizer.get_feature_names()\n",
    "\n",
    "X_train_v = t_vectorizer.transform(X_train)\n",
    "X_test_v = t_vectorizer.transform(X_test)\n",
    "X_train_v.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(242, 13)\n",
      "['cp_0' 'cp_1' 'cp_2' 'cp_3' 'exang_0' 'exang_1' 'slope_0' 'slope_1'\n",
      " 'slope_2' 'thal_0' 'thal_1' 'thal_2' 'thal_3']\n"
     ]
    }
   ],
   "source": [
    "cat_columns = ['cp', 'exang', 'slope', 'thal']\n",
    "num_columns = [c for c in X_train.columns if c not in cat_columns]\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#Create an OneHotEncoder instance\n",
    "encoder = OneHotEncoder(handle_unknown = 'ignore')\n",
    "\n",
    "#Fit on categorical columns\n",
    "encoder.fit(X_train[cat_columns])\n",
    "\n",
    "#Transform on training data\n",
    "X_train_cat_encoded = encoder.transform(X_train[cat_columns])\n",
    "\n",
    "column_names = encoder.get_feature_names(input_features = cat_columns)\n",
    "#print(X_train_cat_encoded.toarray())\n",
    "print(X_train_cat_encoded.todense().shape)\n",
    "print(column_names)\n",
    "\n",
    "X_train_encoded_df = pd.DataFrame(X_train_cat_encoded.todense(),\n",
    "                                  columns = column_names,\n",
    "                                  index = X_train.index)\n",
    "\n",
    "#X_train_encoded_df.head()\n",
    "\n",
    "X_train_encoded = pd.concat([X_train[num_columns], X_train_encoded_df], axis = 1)\n",
    "#X_train_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61, 13)\n",
      "['cp_0' 'cp_1' 'cp_2' 'cp_3' 'exang_0' 'exang_1' 'slope_0' 'slope_1'\n",
      " 'slope_2' 'thal_0' 'thal_1' 'thal_2' 'thal_3']\n"
     ]
    }
   ],
   "source": [
    "#Fit on categorical columns\n",
    "encoder.fit(X_test[cat_columns])\n",
    "\n",
    "#Transform on training data\n",
    "X_test_cat_encoded = encoder.transform(X_test[cat_columns])\n",
    "\n",
    "column_names = encoder.get_feature_names(input_features = cat_columns)\n",
    "#print(X_test_cat_encoded.toarray())\n",
    "print(X_test_cat_encoded.todense().shape)\n",
    "print(column_names)\n",
    "\n",
    "X_test_encoded_df = pd.DataFrame(X_test_cat_encoded.todense(),\n",
    "                                  columns = column_names,\n",
    "                                  index = X_test.index)\n",
    "\n",
    "#print(X_test_encoded_df.head())\n",
    "X_test_encoded = pd.concat([X_test[num_columns], X_test_encoded_df], axis = 1)\n",
    "#X_test_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model(out of the box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.54      0.56        28\n",
      "           1       0.63      0.67      0.65        33\n",
      "\n",
      "    accuracy                           0.61        61\n",
      "   macro avg       0.60      0.60      0.60        61\n",
      "weighted avg       0.60      0.61      0.61        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=1)\n",
    "model.fit(X_train_encoded, y_train)\n",
    "preds = model.predict(X_test_encoded)\n",
    "\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect of max depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth:  1\n",
      "Training Accuracy:  0.7768595041322314\n",
      "Test Accuracy:  0.7213114754098361\n",
      "Max Depth:  3\n",
      "Training Accuracy:  0.8388429752066116\n",
      "Test Accuracy:  0.7377049180327869\n",
      "Max Depth:  5\n",
      "Training Accuracy:  0.9256198347107438\n",
      "Test Accuracy:  0.7049180327868853\n",
      "Max Depth:  7\n",
      "Training Accuracy:  0.9917355371900827\n",
      "Test Accuracy:  0.6065573770491803\n",
      "Max Depth:  9\n",
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.6065573770491803\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "for max_depth in (1, 3, 5, 7, 9):\n",
    "    model = DecisionTreeClassifier(random_state = 1, max_depth=max_depth)\n",
    "    model.fit(X_train_encoded, y_train)\n",
    "    train_preds = model.predict(X_train_encoded)\n",
    "    test_preds = model.predict(X_test_encoded)\n",
    "    #print(f'Max Depth: {max_depth}; Training Accuracy: {accuracy_score(y_train, train_preds)} Test Accuracy: {accuracy_score(y_test, test_preds)})\n",
    "    print('Max Depth: ', max_depth)\n",
    "    print('Training Accuracy: ', accuracy_score(y_train, train_preds))\n",
    "    print('Test Accuracy: ', accuracy_score(y_test, test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort='deprecated',\n",
       "                                              random_state=None,\n",
       "                                              splitter='best'),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'max_depth': (3, 5, 7, 9, 11, 13),\n",
       "                         'min_samples_split': (2, 4, 6, 8, 10)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=make_scorer(f1_score, average=micro), verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_params = {\n",
    "    'max_depth': (3, 5, 7, 9, 11, 13),\n",
    "    'min_samples_split': (2, 4, 6, 8, 10)\n",
    "}\n",
    "\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "scorer = make_scorer(f1_score, average = 'micro')\n",
    "clf = GridSearchCV(DecisionTreeClassifier(), grid_params, scoring = scorer)\n",
    "clf.fit(X_train_encoded, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7728741496598639 {'max_depth': 3, 'min_samples_split': 4}\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_score_, clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(random_state = 1, max_depth=3, min_samples_split = 2)\n",
    "model.fit(X_train_encoded, y_train)\n",
    "y_pred = model.predict(X_test_encoded)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "# Export as dot file\n",
    "export_graphviz(model, out_file='tree.dot', \n",
    "                feature_names = X_train_encoded.columns,\n",
    "                class_names = ['0', '1'],\n",
    "                rounded = True, proportion = False, \n",
    "                precision = 2, filled = True)\n",
    "\n",
    "# Convert to png using system command (requires Graphviz)\n",
    "from subprocess import call\n",
    "call(['dot','-Tpng', 'tree.dot', '-o', 'tree.png', '-Gdpi=600'])\n",
    "\n",
    "# Display in jupyter notebook\n",
    "from IPython.display import Image\n",
    "Image(filename = 'tree.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
